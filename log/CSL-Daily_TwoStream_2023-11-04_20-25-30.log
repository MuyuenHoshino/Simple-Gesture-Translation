Logging to file...
Dataset samples: 18801
######################Training Started######################
epoch   1 | iteration    20 | Loss 3.982672 | Acc 59.58% | WER 100.00%
epoch   1 | iteration    40 | Loss 3.183132 | Acc 62.92% | WER 100.00%
epoch   1 | iteration    60 | Loss 2.762405 | Acc 65.21% | WER 92.03%
epoch   1 | iteration    80 | Loss 2.568488 | Acc 68.54% | WER 89.40%
epoch   1 | iteration   100 | Loss 2.604480 | Acc 69.17% | WER 89.17%
epoch   1 | iteration   120 | Loss 2.893745 | Acc 63.96% | WER 88.39%
epoch   1 | iteration   140 | Loss 2.400736 | Acc 71.46% | WER 87.71%
epoch   1 | iteration   160 | Loss 2.499765 | Acc 67.08% | WER 91.46%
epoch   1 | iteration   180 | Loss 2.398144 | Acc 69.79% | WER 86.54%
epoch   1 | iteration   200 | Loss 2.308388 | Acc 69.38% | WER 89.88%
epoch   1 | iteration   220 | Loss 2.081684 | Acc 73.33% | WER 89.80%
epoch   1 | iteration   240 | Loss 1.970102 | Acc 75.42% | WER 85.15%
epoch   1 | iteration   260 | Loss 2.111839 | Acc 72.29% | WER 86.34%
epoch   1 | iteration   280 | Loss 2.242262 | Acc 70.42% | WER 87.06%
epoch   1 | iteration   300 | Loss 2.079817 | Acc 72.71% | WER 84.82%
epoch   1 | iteration   320 | Loss 2.361340 | Acc 68.75% | WER 89.60%
epoch   1 | iteration   340 | Loss 2.353199 | Acc 70.62% | WER 83.54%
epoch   1 | iteration   360 | Loss 2.471858 | Acc 67.29% | WER 86.40%
epoch   1 | iteration   380 | Loss 2.232485 | Acc 69.17% | WER 89.44%
epoch   1 | iteration   400 | Loss 2.353301 | Acc 68.33% | WER 89.40%
epoch   1 | iteration   420 | Loss 2.541828 | Acc 64.79% | WER 88.86%
epoch   1 | iteration   440 | Loss 2.586926 | Acc 66.04% | WER 86.45%
epoch   1 | iteration   460 | Loss 2.273194 | Acc 70.62% | WER 85.39%
epoch   1 | iteration   480 | Loss 2.454821 | Acc 68.75% | WER 83.09%
epoch   1 | iteration   500 | Loss 2.224653 | Acc 70.42% | WER 82.65%
epoch   1 | iteration   520 | Loss 2.055846 | Acc 72.71% | WER 82.71%
epoch   1 | iteration   540 | Loss 2.197762 | Acc 70.00% | WER 87.15%
epoch   1 | iteration   560 | Loss 1.660876 | Acc 76.46% | WER 88.07%
epoch   1 | iteration   580 | Loss 1.923314 | Acc 73.96% | WER 84.36%
epoch   1 | iteration   600 | Loss 2.374330 | Acc 68.12% | WER 90.02%
epoch   1 | iteration   620 | Loss 2.366357 | Acc 68.96% | WER 86.63%
epoch   1 | iteration   640 | Loss 1.902622 | Acc 73.75% | WER 86.37%
epoch   1 | iteration   660 | Loss 2.061329 | Acc 72.92% | WER 83.32%
epoch   1 | iteration   680 | Loss 2.221062 | Acc 69.79% | WER 87.91%
epoch   1 | iteration   700 | Loss 1.984630 | Acc 74.17% | WER 85.46%
epoch   1 | iteration   720 | Loss 1.654836 | Acc 75.62% | WER 89.20%
epoch   1 | iteration   740 | Loss 2.316635 | Acc 68.54% | WER 86.45%
epoch   1 | iteration   760 | Loss 2.353234 | Acc 67.29% | WER 86.63%
epoch   1 | iteration   780 | Loss 1.860383 | Acc 74.58% | WER 88.56%
epoch   1 | iteration   800 | Loss 2.412848 | Acc 67.29% | WER 85.77%
epoch   1 | iteration   820 | Loss 2.188403 | Acc 70.00% | WER 86.12%
epoch   1 | iteration   840 | Loss 2.757837 | Acc 62.92% | WER 84.46%
epoch   1 | iteration   860 | Loss 1.971431 | Acc 74.38% | WER 76.97%
epoch   1 | iteration   880 | Loss 1.976794 | Acc 71.25% | WER 86.51%
epoch   1 | iteration   900 | Loss 2.352460 | Acc 67.08% | WER 85.10%
epoch   1 | iteration   920 | Loss 2.256050 | Acc 68.54% | WER 87.72%
epoch   1 | iteration   940 | Loss 2.162030 | Acc 70.83% | WER 85.86%
epoch   1 | iteration   960 | Loss 1.905958 | Acc 72.92% | WER 88.11%
epoch   1 | iteration   980 | Loss 2.154664 | Acc 69.17% | WER 87.20%
epoch   1 | iteration  1000 | Loss 1.917767 | Acc 73.96% | WER 87.15%
epoch   1 | iteration  1020 | Loss 2.222941 | Acc 70.62% | WER 86.32%
epoch   1 | iteration  1040 | Loss 1.953688 | Acc 72.71% | WER 82.94%
epoch   1 | iteration  1060 | Loss 2.192951 | Acc 68.12% | WER 92.40%
epoch   1 | iteration  1080 | Loss 2.190128 | Acc 69.38% | WER 85.25%
epoch   1 | iteration  1100 | Loss 2.342585 | Acc 68.12% | WER 82.23%
epoch   1 | iteration  1120 | Loss 2.359381 | Acc 68.12% | WER 85.29%
epoch   1 | iteration  1140 | Loss 2.190252 | Acc 70.83% | WER 86.08%
Average Training Loss of Epoch 1: 2.357252 | Acc: 69.07% | WER 87.49%
####################Epoch 1 Model Saved#####################
epoch   2 | iteration    20 | Loss 2.079571 | Acc 71.67% | WER 82.38%
epoch   2 | iteration    40 | Loss 2.009496 | Acc 71.67% | WER 87.37%
epoch   2 | iteration    60 | Loss 2.088771 | Acc 69.58% | WER 84.84%
epoch   2 | iteration    80 | Loss 2.293922 | Acc 69.58% | WER 81.47%
epoch   2 | iteration   100 | Loss 2.271110 | Acc 67.92% | WER 86.61%
epoch   2 | iteration   120 | Loss 2.384522 | Acc 66.88% | WER 89.23%
epoch   2 | iteration   140 | Loss 2.121500 | Acc 69.58% | WER 84.39%
epoch   2 | iteration   160 | Loss 2.084669 | Acc 70.62% | WER 87.65%
epoch   2 | iteration   180 | Loss 1.918440 | Acc 73.33% | WER 86.61%
epoch   2 | iteration   200 | Loss 2.424362 | Acc 65.42% | WER 85.67%
epoch   2 | iteration   220 | Loss 1.828117 | Acc 72.08% | WER 83.44%
epoch   2 | iteration   240 | Loss 2.042301 | Acc 71.04% | WER 85.76%
epoch   2 | iteration   260 | Loss 2.259432 | Acc 68.33% | WER 83.24%
epoch   2 | iteration   280 | Loss 1.829903 | Acc 74.17% | WER 80.09%
epoch   2 | iteration   300 | Loss 1.851205 | Acc 73.75% | WER 83.69%
epoch   2 | iteration   320 | Loss 2.282579 | Acc 70.83% | WER 84.98%
epoch   2 | iteration   340 | Loss 2.180804 | Acc 70.62% | WER 81.63%
epoch   2 | iteration   360 | Loss 1.947623 | Acc 72.71% | WER 81.07%
epoch   2 | iteration   380 | Loss 2.127245 | Acc 70.00% | WER 84.04%
epoch   2 | iteration   400 | Loss 2.315893 | Acc 67.29% | WER 86.36%
epoch   2 | iteration   420 | Loss 2.221576 | Acc 69.17% | WER 85.02%
epoch   2 | iteration   440 | Loss 1.931350 | Acc 72.08% | WER 82.07%
epoch   2 | iteration   460 | Loss 1.893757 | Acc 73.54% | WER 80.21%
epoch   2 | iteration   480 | Loss 2.225358 | Acc 68.33% | WER 83.30%
epoch   2 | iteration   500 | Loss 1.910139 | Acc 74.58% | WER 79.97%
epoch   2 | iteration   520 | Loss 1.869215 | Acc 73.33% | WER 85.72%
epoch   2 | iteration   540 | Loss 2.286092 | Acc 68.12% | WER 84.66%
epoch   2 | iteration   560 | Loss 2.273748 | Acc 68.75% | WER 81.75%
epoch   2 | iteration   580 | Loss 1.794747 | Acc 73.75% | WER 82.34%
epoch   2 | iteration   600 | Loss 2.336777 | Acc 67.08% | WER 84.34%
epoch   2 | iteration   620 | Loss 1.931987 | Acc 73.12% | WER 82.43%
epoch   2 | iteration   640 | Loss 2.085964 | Acc 68.75% | WER 82.70%
epoch   2 | iteration   660 | Loss 2.567616 | Acc 64.17% | WER 83.16%
epoch   2 | iteration   680 | Loss 2.216692 | Acc 71.04% | WER 83.69%
epoch   2 | iteration   700 | Loss 1.973045 | Acc 72.29% | WER 80.12%
epoch   2 | iteration   720 | Loss 2.002183 | Acc 72.92% | WER 83.10%
epoch   2 | iteration   740 | Loss 1.985252 | Acc 71.67% | WER 86.27%
epoch   2 | iteration   760 | Loss 1.963559 | Acc 72.50% | WER 83.54%
epoch   2 | iteration   780 | Loss 2.052742 | Acc 68.96% | WER 87.54%
epoch   2 | iteration   800 | Loss 1.823478 | Acc 73.33% | WER 81.76%
epoch   2 | iteration   820 | Loss 1.967976 | Acc 71.04% | WER 85.94%
epoch   2 | iteration   840 | Loss 2.548791 | Acc 64.79% | WER 85.54%
epoch   2 | iteration   860 | Loss 1.870731 | Acc 73.75% | WER 83.71%
epoch   2 | iteration   880 | Loss 2.072459 | Acc 70.21% | WER 90.21%
epoch   2 | iteration   900 | Loss 2.186111 | Acc 70.00% | WER 85.46%
epoch   2 | iteration   920 | Loss 2.381385 | Acc 65.62% | WER 88.53%
epoch   2 | iteration   940 | Loss 1.898517 | Acc 72.50% | WER 80.43%
epoch   2 | iteration   960 | Loss 1.800759 | Acc 73.96% | WER 81.86%
epoch   2 | iteration   980 | Loss 2.360750 | Acc 66.04% | WER 83.94%
epoch   2 | iteration  1000 | Loss 1.765565 | Acc 73.54% | WER 78.70%
epoch   2 | iteration  1020 | Loss 1.978839 | Acc 72.08% | WER 82.91%
epoch   2 | iteration  1040 | Loss 2.111192 | Acc 70.62% | WER 84.99%
epoch   2 | iteration  1060 | Loss 2.020386 | Acc 71.25% | WER 89.19%
epoch   2 | iteration  1080 | Loss 1.871146 | Acc 73.75% | WER 79.28%
epoch   2 | iteration  1100 | Loss 2.159492 | Acc 69.17% | WER 87.12%
epoch   2 | iteration  1120 | Loss 2.181524 | Acc 71.25% | WER 80.12%
epoch   2 | iteration  1140 | Loss 1.914070 | Acc 74.38% | WER 77.98%
Average Training Loss of Epoch 2: 2.094747 | Acc: 70.71% | WER 83.36%
####################Epoch 2 Model Saved#####################
epoch   3 | iteration    20 | Loss 2.111350 | Acc 69.58% | WER 84.06%
epoch   3 | iteration    40 | Loss 1.743205 | Acc 73.33% | WER 82.34%
epoch   3 | iteration    60 | Loss 1.925630 | Acc 72.08% | WER 81.98%
